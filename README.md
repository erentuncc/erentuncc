## Hi there ğŸ‘‹
FÄ°SK DATASET PROJECT SUMMARY
Ä°lk olarak, veri analizi, gÃ¶rselleÅŸtirme ve makine Ã¶ÄŸrenimi iÃ§in gerekli kÃ¼tÃ¼phaneler olan Pandas, NumPy, Matplotlib, Scikit-learn, OS, Struct, Warnings, TensorFlow, Pillow ve Keras'Ä± iÃ§e aktardÄ±m. AyrÄ±ca, uyarÄ±larÄ± gÃ¶z ardÄ± etmek iÃ§in bir ayar yaptÄ±m. 
Sonra , balÄ±k gÃ¶rÃ¼ntÃ¼lerinin bulunduÄŸu dizindeki tÃ¼m .png dosyalarÄ±nÄ± bulup, her birinin etiketini ve dosya yolunu Ã§Ä±kardÄ±m. Bu bilgileri iki listeye (label ve path) ekledim. Daha sonra, bu listeleri kullanarak bir Pandas DataFrame oluÅŸturdum ve path ile label sÃ¼tunlarÄ±nÄ± doldurdum. AyrÄ±ca, "GT" (Ground Truth) klasÃ¶rlerini gÃ¶z ardÄ± ettim. 
Verileri inceleme aÅŸamasÄ±nda ilk olarak, , oluÅŸturduÄŸum DataFrame'in ilk beÅŸ satÄ±rÄ±nÄ± ve son beÅŸ satÄ±rÄ±nÄ± gÃ¶rÃ¼ntÃ¼ledim. Bu, veri yapÄ±sÄ±nÄ± ve iÃ§eriÄŸini kontrol etmeme yardÄ±mcÄ± oldu. df.head() ve df.tail() komutu, path ve label sÃ¼tunlarÄ±yla birlikte ilk birkaÃ§ Ã¶rneÄŸi ve son birkaÃ§ gÃ¶stererek veri setinin doÄŸru bir ÅŸekilde yÃ¼klendiÄŸini doÄŸrulamamÄ± saÄŸladÄ±.  AyrÄ±ca burada df.shape komutunu kullanarak DataFrame'in boyutunu kontrol ettim. Bu, toplam kayÄ±t sayÄ±sÄ±nÄ± ve sÃ¼tun sayÄ±sÄ±nÄ± gÃ¶sterir. BÃ¶ylece veri setimin bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼ ve yapÄ±sÄ±nÄ± daha iyi anlayarak, analiz ve modelleme aÅŸamalarÄ±nda hangi verilerle Ã§alÄ±ÅŸacaÄŸÄ±mÄ± belirlemiÅŸ oldum.
 Burada ayrÄ±ca, print(df) komutunu kullanarak DataFrame'in tamamÄ±nÄ± ekrana yazdÄ±rdÄ±m. Bu, tÃ¼m veri setini gÃ¶zlemlememi saÄŸladÄ± ve path ile label sÃ¼tunlarÄ±ndaki verilerin doÄŸruluÄŸunu kontrol etmeme yardÄ±mcÄ± oldu. 
 BÃ¶ylece, veri setinin iÃ§eriÄŸi hakkÄ±nda genel bir bakÄ±ÅŸ elde ettim. 
 SonrasÄ±nda , df['label'].unique() komutunu kullanarak veri setindeki benzersiz etiketleri Ã§Ä±kardÄ±m. ArdÄ±ndan, her bir etiket iÃ§in bir Ã¶rnek gÃ¶rÃ¼ntÃ¼yÃ¼ gÃ¶steren 3x3 bir alt grafik oluÅŸturmak Ã¼zere plt.subplots kullandÄ±m. Her benzersiz etiket iÃ§in ilk gÃ¶rÃ¼ntÃ¼yÃ¼ okuyup alt grafik Ã¼zerinde gÃ¶rÃ¼ntÃ¼ledim ve baÅŸlÄ±k olarak etiket adÄ±nÄ± ekledim. Bu, her tÃ¼rÃ¼n temsilini gÃ¶rselleÅŸtirerek modelin Ã¶ÄŸrenmesi gereken sÄ±nÄ±flarÄ± anlamama yardÄ±mcÄ± oldu. 
 Daha sonra , gÃ¶rÃ¼ntÃ¼leri yÃ¼klemek ve Ã¶n iÅŸlemek iÃ§in bir fonksiyon (load_images) tanÄ±mladÄ±m.
Fonksiyonun Ä°ÅŸlevi:DataFrame'deki her bir gÃ¶rÃ¼ntÃ¼ dosyasÄ±nÄ± aÃ§Ä±p belirli bir boyuta (img_size) yeniden boyutlandÄ±rdÄ±m.
GÃ¶rÃ¼ntÃ¼leri normalleÅŸtirerek (0-1 aralÄ±ÄŸÄ±na Ã¶lÃ§ekleyerek) modelin eÄŸitimine uygun hale getirdim.
Her bir gÃ¶rÃ¼ntÃ¼yÃ¼ ve karÅŸÄ±lÄ±k gelen etiketini listelere ekledim.
Ã‡Ä±ktÄ±: Fonksiyon, iÅŸlenmiÅŸ gÃ¶rÃ¼ntÃ¼lerin ve etiketlerin NumPy dizileri olarak dÃ¶ndÃ¼rÃ¼lmesini saÄŸlÄ±yor. Bu, daha sonra model eÄŸitiminde kullanÄ±lmak Ã¼zere veri setini hazÄ±r hale getiriyor.

Sonra , veri setini eÄŸitim ve test setlerine ayÄ±rdÄ±m.
Fonksiyon KullanÄ±mÄ±: train_test_split fonksiyonunu kullanarak veri setimin %80'ini eÄŸitim, %20'sini test iÃ§in ayÄ±rdÄ±m.
test_size: Test setinin boyutunu belirliyor (bu durumda %20).
random_state: SonuÃ§larÄ±n tekrarlanabilir olmasÄ±nÄ± saÄŸlamak iÃ§in bir rastgelelik tohum deÄŸeri ayarladÄ±m.
stratify: Etiketlerin daÄŸÄ±lÄ±mÄ±nÄ±n eÄŸitim ve test setlerinde benzer olmasÄ±nÄ± saÄŸlamak iÃ§in kullanÄ±ldÄ±, bÃ¶ylece her iki set de her etiket iÃ§in benzer oranlara sahip olur.
SonuÃ§: EÄŸitim ve test setlerinin iÃ§eriÄŸini yazdÄ±rarak ayÄ±rmanÄ±n baÅŸarÄ±lÄ± olup olmadÄ±ÄŸÄ±nÄ± kontrol ettim. Bu, modelin daha iyi genelleÅŸtirilmesi iÃ§in kritik bir adÄ±mdÄ±r.

Daha sonra, eÄŸitim ve test setlerindeki gÃ¶rÃ¼ntÃ¼leri yÃ¼kledim ve etiketleri one-hot encoding formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rdÃ¼m.
GÃ¶rsellerin YÃ¼klenmesi:load_images fonksiyonunu kullanarak, X_train_df ve X_test_df DataFrame'lerinden gÃ¶rÃ¼ntÃ¼leri ve etiketleri yÃ¼kledim. X_train ve X_test olarak gÃ¶rÃ¼ntÃ¼leri, y_train ve y_test olarak etiketleri elde ettim.
Etiketlerin One-Hot Encoding'e DÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi:Ã–ncelikle, benzersiz etiketleri Ã§Ä±kardÄ±m ve her bir etiket iÃ§in bir indeks belirledim (sÄ±nÄ±f haritasÄ± oluÅŸturma).
y_train ve y_test dizilerini, bu haritayÄ± kullanarak sayÄ±sal deÄŸerlere dÃ¶nÃ¼ÅŸtÃ¼rdÃ¼m.
to_categorical fonksiyonunu kullanarak etiketleri one-hot encoding formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rdÃ¼m. Bu, modelin etiketleri daha etkili bir ÅŸekilde Ã¶ÄŸrenmesine yardÄ±mcÄ± olur.
SonuÃ§: EÄŸitim ve test setlerinin boyutlarÄ±nÄ± yazdÄ±rarak, yÃ¼klenen gÃ¶rÃ¼ntÃ¼lerin ve dÃ¶nÃ¼ÅŸtÃ¼rÃ¼len etiketlerin doÄŸru bir ÅŸekilde hazÄ±rlandÄ±ÄŸÄ±nÄ± kontrol ettim.

Modeli eÄŸitme aÅŸamasÄ±nda, bir yapay sinir aÄŸÄ± modeli oluÅŸturdum ve derledim.

Model OluÅŸturma:Sequential sÄ±nÄ±fÄ±nÄ± kullanarak katmanlarÄ± sÄ±rayla eklediÄŸim bir model oluÅŸturdum.
Ä°lk katman olarak Flatten kullandÄ±m; bu, 64x64 boyutundaki gÃ¶rÃ¼ntÃ¼leri dÃ¼zleÅŸtirerek bir vektÃ¶r haline getiriyor.
Ä°ki adet gizli katman ekledim:
Ä°lk katman: 128 nÃ¶ron ve relu aktivasyon fonksiyonu.
Ä°kinci katman: 64 nÃ¶ron ve relu aktivasyon fonksiyonu.
Son katman: len(classes) kadar nÃ¶ron, softmax aktivasyon fonksiyonu ile Ã§Ä±kÄ±ÅŸ veriyor. Bu, sÄ±nÄ±flar arasÄ±ndaki olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ±nÄ± saÄŸlÄ±yor.


Modeli Derleme:adam optimizasyon algoritmasÄ±nÄ± kullandÄ±m.
KayÄ±p fonksiyonu olarak categorical_crossentropy seÃ§tim, bu da Ã§oklu sÄ±nÄ±f sÄ±nÄ±flandÄ±rma problemleri iÃ§in uygun.
Modelin performansÄ±nÄ± deÄŸerlendirmek iÃ§in accuracy metriÄŸini ekledim.
Bu adÄ±mda, modelim eÄŸitim ve test aÅŸamalarÄ±na hazÄ±r hale getirildi.

EÄŸitim sÃ¼recinin sonunda, modelin Ã¶ÄŸrenme sÃ¼recini ve performansÄ±nÄ± takip edebilmek iÃ§in history nesnesinde eÄŸitim ve doÄŸrulama kayÄ±plarÄ±nÄ± ve doÄŸruluklarÄ±nÄ± sakladÄ±m. Bu, modelin geliÅŸimini analiz etmemi saÄŸlayacak. 

DeÄŸerlendirme aÅŸamasÄ±nda ,  eÄŸitimini tamamladÄ±ÄŸÄ±m modelin test seti Ã¼zerindeki performansÄ±nÄ± deÄŸerlendirdim.

Modelin DeÄŸerlendirilmesi:
evaluate fonksiyonunu kullanarak, test verileri (X_test ve y_test) ile modelin kaybÄ±nÄ± (test_loss) ve doÄŸruluÄŸunu (test_acc) hesapladÄ±m.
SonuÃ§:
Test setindeki doÄŸruluk deÄŸerini ekrana yazdÄ±rdÄ±m. Bu, modelin daha Ã¶nce gÃ¶rmediÄŸi verilerle ne kadar iyi performans gÃ¶sterdiÄŸini anlamamÄ± saÄŸladÄ±. YÃ¼ksek bir doÄŸruluk, modelin genel baÅŸarÄ±sÄ±nÄ± gÃ¶sterirken, dÃ¼ÅŸÃ¼k bir doÄŸruluk modelin geliÅŸtirilmesi gerektiÄŸini iÅŸaret eder.

Son olarak,  modelin eÄŸitim sÃ¼recini ve performansÄ±nÄ± gÃ¶rselleÅŸtirdim.

DoÄŸruluk GrafiÄŸi:

plt.plot fonksiyonu ile eÄŸitim ve doÄŸrulama doÄŸruluÄŸunu Ã§izdim.
history.history['accuracy'] ile eÄŸitim doÄŸruluÄŸunu, history.history['val_accuracy'] ile doÄŸrulama doÄŸruluÄŸunu gÃ¶sterdim.
X eksenine epok sayÄ±sÄ±nÄ±, Y eksenine doÄŸruluk deÄŸerini ekledim.
Grafik DetaylarÄ±:

Grafikte iki farklÄ± Ã§izgi ile eÄŸitim ve doÄŸrulama doÄŸruluÄŸunu temsil ettim.
plt.legend() ile Ã§izgilerin etiketlerini ekledim ve plt.show() ile grafiÄŸi gÃ¶rÃ¼ntÃ¼ledim.
Bu gÃ¶rselleÅŸtirme, modelin eÄŸitim sÃ¼recindeki ilerlemesini ve potansiyel aÅŸÄ±rÄ± Ã¶ÄŸrenme (overfitting) durumlarÄ±nÄ± anlamama yardÄ±mcÄ± oldu. EÄŸitim ve doÄŸrulama doÄŸruluklarÄ± arasÄ±ndaki farkÄ± gÃ¶zlemleyerek modelin performansÄ±nÄ± deÄŸerlendirdim.



